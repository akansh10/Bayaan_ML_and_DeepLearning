{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning for Image Classification\n",
    "===\n",
    "\n",
    "We will use K-NN and SVM on MNIST and Fashion-MNIST Dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbors\n",
    "\n",
    "kNN is a simple machine learning algorithm that depends on distances among data points for classification. The distances are usually measured using either Manhattan distance or Euclidean distance.\n",
    "\n",
    "## The MNIST Dataset\n",
    "\n",
    "We load the MNIST dataset using `cv2.imread()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "mnist = cv2.imread('./datasets/digits.png', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array([np.hsplit(row, 100) for row in np.vsplit(mnist, 50)], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 100, 20, 20)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for visualization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(features[0, 0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Partition\n",
    "\n",
    "Split the dataset to 50-50 for arithmetic convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = features[:, :50].reshape(-1, (20 * 20))\n",
    "test_features = features[:, 50:100].reshape(-1, (20 * 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.arange(10)\n",
    "train_labels = np.repeat(k, 250).reshape(-1, 1)\n",
    "test_labels = train_labels.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The kNN Model\n",
    "\n",
    "Let's create the kNN model using `cv2.ml.KNearest_create()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv2.ml.KNearest_create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the kNN\n",
    "\n",
    "When it's actually just memorizing the data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(train_features, cv2.ml.ROW_SAMPLE, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the trained kNN\n",
    "\n",
    "Classify test features using trained kNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use k = 3\n",
    "ret, result, neighbors, dist = model.findNearest(test_features, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure Model Accuracy\n",
    "\n",
    "Get the test accuracy of the trained kNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the results are correct\n",
    "matches = np.equal(result, test_labels)\n",
    "\n",
    "# convert bool to int\n",
    "matches = matches.astype(np.int)\n",
    "\n",
    "# count the correct predictions\n",
    "correct = np.count_nonzero(matches)\n",
    "\n",
    "# compute the accuracy\n",
    "accuracy = (correct * 100.00) / result.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct : 2291\n",
      "Accuracy : 91.64\n"
     ]
    }
   ],
   "source": [
    "# print('Matches : {}'.format(matches))\n",
    "print('Correct : {}'.format(correct))\n",
    "print('Accuracy : {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Fashion-MNIST Dataset\n",
    "\n",
    "The Fashion-MNIST dataset was introduced as an alternative to MNIST. The Fashion-MNIST dataset we have has 30 images per row, and 30 images per column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "fashion = cv2.imread('./datasets/fashion.png', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(840, 840)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `840x840` size of the dataset, and `30x30` images in the dataset, we have each image at `28x28` pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array([np.hsplit(row, 30) for row in np.vsplit(fashion, 30)], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 30, 28, 28)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(features[0, 0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Partition\n",
    "\n",
    "Split the dataset to 50-50 for arithmetic convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = features[:, :15].reshape(-1, (28 * 28))\n",
    "test_features = features[:, 15:30].reshape(-1, (28 * 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.arange(10)\n",
    "train_labels = np.repeat(k, 45).reshape(-1, 1)\n",
    "test_labels = train_labels.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The kNN Model\n",
    "\n",
    "Let's create the kNN model using `cv2.ml.KNearest_create()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv2.ml.KNearest_create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the kNN\n",
    "\n",
    "When it's actually just memorizing the data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(train_features, cv2.ml.ROW_SAMPLE, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the trained kNN\n",
    "\n",
    "Classify test features using trained kNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use k = 3, other values of k can be used.\n",
    "ret, result, neighbors, dist = model.findNearest(test_features, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure Model Accuracy\n",
    "\n",
    "Get the test accuracy of the trained kNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the results are correct\n",
    "matches = np.equal(result, test_labels)\n",
    "\n",
    "# convert bool to int\n",
    "matches = matches.astype(np.int)\n",
    "\n",
    "# count the correct predictions\n",
    "correct = np.count_nonzero(matches)\n",
    "\n",
    "# compute the accuracy\n",
    "accuracy = (correct * 100.00) / result.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct : 319\n",
      "Accuracy : 70.88888888888889\n"
     ]
    }
   ],
   "source": [
    "# print('Matches : {}'.format(matches))\n",
    "print('Correct : {}'.format(correct))\n",
    "print('Accuracy : {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine\n",
    "\n",
    "Finds the hyperplane which best separates the dataset into  two classes.\n",
    "\n",
    "## The MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "mnist = cv2.imread('./datasets/digits.png', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array([np.hsplit(row, 100) for row in np.vsplit(mnist, 50)], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 100, 20, 20)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Partition\n",
    "\n",
    "Split the dataset to 50-50 for arithmetic convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = features[:, :50].reshape(-1, (20 * 20))\n",
    "test_features = features[:, 50:100].reshape(-1, (20 * 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.arange(10)\n",
    "train_labels = np.repeat(k, 250).reshape(-1, 1)\n",
    "test_labels = train_labels.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv2.ml.SVM_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.setKernel(cv2.ml.SVM_LINEAR)\n",
    "model.setC(2.67)\n",
    "model.setGamma(5.383)\n",
    "model.setType(cv2.ml.SVM_C_SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(train_features, cv2.ml.ROW_SAMPLE, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Trained SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure Model Accuracy\n",
    "\n",
    "Get the test accuracy of the trained SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = np.equal(result[1], test_labels)\n",
    "matches = matches.astype(np.int)\n",
    "correct = np.count_nonzero(matches)\n",
    "accuracy = (correct * 100.00) / result[1].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct : 2261\n",
      "Accuracy : 90.44\n"
     ]
    }
   ],
   "source": [
    "# print('Matches : {}'.format(matches))\n",
    "print('Correct : {}'.format(correct))\n",
    "print('Accuracy : {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Fashion-MNIST Dataset\n",
    "\n",
    "The Fashion-MNIST dataset was introduced as an alternative to MNIST. The Fashion-MNIST dataset we have has 30 images per row, and 30 images per column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "fashion = cv2.imread('./datasets/fashion.png', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(840, 840)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `840x840` size of the dataset, and `30x30` images in the dataset, we have each image at `28x28` pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array([np.hsplit(row, 30) for row in np.vsplit(fashion, 30)], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 30, 28, 28)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Partition\n",
    "\n",
    "Split the dataset to 50-50 for arithmetic convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = features[:, :15].reshape(-1, (28 * 28))\n",
    "test_features = features[:, 15:30].reshape(-1, (28 * 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.arange(10)\n",
    "train_labels = np.repeat(k, 45).reshape(-1, 1)\n",
    "test_labels = train_labels.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv2.ml.SVM_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.setKernel(cv2.ml.SVM_LINEAR)\n",
    "model.setC(2.67)\n",
    "model.setGamma(5.383)\n",
    "model.setType(cv2.ml.SVM_C_SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(train_features, cv2.ml.ROW_SAMPLE, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Trained SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure Model Accuracy\n",
    "\n",
    "Get the test accuracy of the trained SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = np.equal(result[1], test_labels)\n",
    "matches = matches.astype(np.int)\n",
    "correct = np.count_nonzero(matches)\n",
    "accuracy = (correct * 100.00) / result[1].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct : 336\n",
      "Accuracy : 74.66666666666667\n"
     ]
    }
   ],
   "source": [
    "# print('Matches : {}'.format(matches))\n",
    "print('Correct : {}'.format(correct))\n",
    "print('Accuracy : {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
